{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicolasfeller/anaconda/envs/tfdeeplearning/lib/python3.5/site-packages/matplotlib/font_manager.py:280: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a476fa632bb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from six.moves import xrange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import LSTM,GRU\n",
    "from keras.layers import Lambda\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "\n",
    "from keras.optimizers import RMSprop,adam\n",
    "from keras.callbacks import History\n",
    "\n",
    "import wtte.weibull as weibull\n",
    "import wtte.wtte as wtte\n",
    "\n",
    "from wtte.wtte import WeightWatcher\n",
    "\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_data(n_timesteps, every_nth,n_repeats,noise_level,n_features,use_censored = True):\n",
    "    def get_equal_spaced(n, every_nth):\n",
    "        # create some simple data of evenly spaced events recurring every_nth step\n",
    "        # Each is on (time,batch)-format\n",
    "        events = np.array([np.array(xrange(n)) for _ in xrange(every_nth)])\n",
    "        events = events + np.array(xrange(every_nth)).reshape(every_nth, 1) + 1\n",
    "\n",
    "        tte_actual = every_nth - 1 - events % every_nth\n",
    "\n",
    "        was_event = (events % every_nth == 0) * 1.0\n",
    "        was_event[:, 0] = 0.0\n",
    "\n",
    "        events = tte_actual == 0\n",
    "\n",
    "        is_censored = (events[:, ::-1].cumsum(1)[:, ::-1] == 0) * 1\n",
    "        tte_censored = is_censored[:, ::-1].cumsum(1)[:, ::-1] * is_censored\n",
    "        tte_censored = tte_censored + (1 - is_censored) * tte_actual\n",
    "\n",
    "        events = np.copy(events.T * 1.0)\n",
    "        tte_actual = np.copy(tte_actual.T * 1.0)\n",
    "        tte_censored = np.copy(tte_censored.T * 1.0)\n",
    "        was_event = np.copy(was_event.T * 1.0)\n",
    "        not_censored = 1 - np.copy(is_censored.T * 1.0)\n",
    "\n",
    "        return tte_censored, not_censored, was_event, events, tte_actual\n",
    "    \n",
    "    tte_censored,not_censored,was_event,events,tte_actual = get_equal_spaced(n=n_timesteps,every_nth=every_nth)\n",
    "\n",
    "    # From https://keras.io/layers/recurrent/\n",
    "    # input shape rnn recurrent if return_sequences: (nb_samples, timesteps, input_dim)\n",
    "\n",
    "    u_train      = not_censored.T.reshape(n_sequences,n_timesteps,1)\n",
    "    x_train      = was_event.T.reshape(n_sequences,n_timesteps,1)\n",
    "    tte_censored = tte_censored.T.reshape(n_sequences,n_timesteps,1)\n",
    "    y_train      = np.append(tte_censored,u_train,axis=2) # (n_sequences,n_timesteps,2)\n",
    "\n",
    "    u_test       = np.ones(shape=(n_sequences,n_timesteps,1))\n",
    "    x_test       = np.copy(x_train)\n",
    "    tte_actual   = tte_actual.T.reshape(n_sequences,n_timesteps,1)\n",
    "    y_test       = np.append(tte_actual,u_test,axis=2) # (n_sequences,n_timesteps,2)\n",
    "\n",
    "    if not use_censored:\n",
    "        x_train = np.copy(x_test)\n",
    "        y_train = np.copy(y_test)\n",
    "    # Since the above is deterministic perfect fit is feasible. \n",
    "    # More noise->more fun so add noise to the training data:\n",
    "    \n",
    "    x_train = np.tile(x_train.T,n_repeats).T\n",
    "    y_train = np.tile(y_train.T,n_repeats).T\n",
    "\n",
    "    # Try with more than one feature TODO\n",
    "    x_train_new = np.zeros([x_train.shape[0],x_train.shape[1],n_features])\n",
    "    x_test_new = np.zeros([x_test.shape[0],x_test.shape[1],n_features])\n",
    "    for f in xrange(n_features):\n",
    "        x_train_new[:,:,f] = x_train[:,:,0]\n",
    "        x_test_new[:,:,f]  = x_test[:,:,0]\n",
    "        \n",
    "    x_train = x_train_new\n",
    "    x_test  = x_test_new\n",
    "    \n",
    "    # xtrain is signal XOR noise with probability noise_level\n",
    "    noise = np.random.binomial(1,noise_level,size=x_train.shape)\n",
    "    x_train = x_train+noise-x_train*noise\n",
    "    return y_train,x_train, y_test,x_test,events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_timesteps    = 200\n",
    "n_sequences = every_nth = 80\n",
    "n_features = 1\n",
    "n_repeats = 1000\n",
    "noise_level = 0.005\n",
    "use_censored = True\n",
    "\n",
    "y_train,x_train, y_test,x_test,events = get_data(n_timesteps, every_nth,n_repeats,noise_level,n_features,use_censored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfdeeplearning]",
   "language": "python",
   "name": "conda-env-tfdeeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
