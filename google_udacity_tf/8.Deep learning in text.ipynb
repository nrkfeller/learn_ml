{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Learning\n",
    "### Semantic ambiguity\n",
    "use of different word to mean the same thing, cat and kitty means the same are are very different!\n",
    "\n",
    "We need to collect a lot of label data!\n",
    "\n",
    "### Unsupervised learning!\n",
    "training without any labels! its easy top find text. wikipedia is plenty of text to train on.\n",
    "\n",
    "just pair similar words in similar context\n",
    "\n",
    "### Embeddings\n",
    "cat cam be replaces by kitty in many context. we should try to learn about context. we want cat and kitty to exist in the same location in the hyperspace!\n",
    "\n",
    "embeddings = mapping words to vectors\n",
    "\n",
    "Cat like things are represented by vectors that are very similar! It allows our model to generalize\n",
    "\n",
    "### Word2Vec\n",
    "Very simple but works very well\n",
    "\n",
    "\"The quick brown fox jumps over the lazy dog\"\n",
    "\n",
    "1. map each of these words to a random vector\n",
    "2. context is the words that are nearby\n",
    "3. We use logistic regression\n",
    "\n",
    "### tSNE\n",
    "Way to visualize hyperspace where we are preserving the neighborhood structure of the data.\n",
    "\n",
    "### Comparing ebeddings\n",
    "Its better to use cosine distance instead of L2! this is because the length of the embedding vector is not relevant to the classification. Euclidean will create huge distances because of high dimensionality, but cosine distance squashes it and doesnt care about the size of vector.\n",
    "\n",
    "word -> embed to vector -> feed to linear model -> sofgtmax -> cross entropy\n",
    "\n",
    "Instead of softmaxing to all the possible words. just sample x words and pick the closest. just pretend the sample space only contains x words. This actually works pretty well, its makes it much faster and the performance is not really affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tftut",
   "language": "python",
   "name": "tftut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
